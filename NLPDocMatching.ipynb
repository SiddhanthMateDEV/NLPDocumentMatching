{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/siddhanthmate/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from doctest import NORMALIZE_WHITESPACE\n",
    "from encodings import normalize_encoding\n",
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CLASS TO MATCH PDF USING BERT AND TD-IDF'''\n",
    "\n",
    "class userinput_pdfdocmatching():\n",
    "\n",
    "    def __init__(self):\n",
    "        documents=pd.DataFrame(columns=['text'])\n",
    "        #num_files=int(input('Enter the number of files you want to read'))\n",
    "        self.openedfiles=self.open_files()  \n",
    "        self.cleaned_doc=self.document_cleaning()\n",
    "        self.sparse = self.tfidf_vectorizer()\n",
    "\n",
    "        #num_files=4\n",
    "        #file_names=['/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV.pdf','/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV2023.pdf',\n",
    "        #'/Users/siddhanthmate/Desktop/imperial/ielts.pdf','/Users/siddhanthmate/Desktop/imperial/SOP_ICL.pdf']\n",
    "        #for i in range(0,num_files):\n",
    "        #   file_names.append(str(input('Enter the file name')))\n",
    "\n",
    "    # file_names=['/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV.pdf','/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV2023.pdf']\n",
    "    def open_files(self):\n",
    "        #num_files=int(input('Enter the number of files you want to read'))\n",
    "        #file_names=[]\n",
    "        #for i in range(0,num_files):\n",
    "            #file_names.append(str(input('Enter the file name')))\n",
    "    \n",
    "        num_files=4\n",
    "        file_names=['/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV.pdf','/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV2023.pdf',\n",
    "        '/Users/siddhanthmate/Desktop/imperial/ielts.pdf','/Users/siddhanthmate/Desktop/imperial/SOP_ICL.pdf']\n",
    "        reader = pypdf.PdfReader(\"/Users/siddhanthmate/Desktop/cv/SiddhanthMateCV.pdf\")\n",
    "        text_arr=[]\n",
    "\n",
    "        \n",
    "        for i in range(0,num_files):\n",
    "            reader = pypdf.PdfReader(file_names[i])\n",
    "            page = reader.pages[0]\n",
    "            text=page.extract_text()\n",
    "            text_arr.append(text)\n",
    "        documents=pd.DataFrame(data=text_arr,columns=['text'])\n",
    "        return documents\n",
    "\n",
    "    def document_cleaning(self):\n",
    "        documents=self.openedfiles\n",
    "        stop_words_l=stopwords.words('english')\n",
    "        documents['text']=documents.text.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
    "        return documents\n",
    "\n",
    "    def tfidf_vectorizer(self):\n",
    "        doc=self.cleaned_doc\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        sparse_matrix = tfidf_vectorizer.fit_transform(doc['text'])\n",
    "        #pairwise_similarities=np.dot(sparse_matrix[0,:],sparse_matrix[1:,:].T).toarray()\n",
    "        pairwise_similarities=sparse_matrix[0,:].dot(sparse_matrix[1:4,:].T).toarray()\n",
    "        pairwise_differences=euclidean_distances(sparse_matrix)\n",
    "        return sparse_matrix,pairwise_similarities,pairwise_differences\n",
    "\n",
    "\n",
    "    def get_similar_documents(self):\n",
    "        doc=self.cleaned_doc\n",
    "        sparse_matrix,pairwise_similarities,pairwise_differences=self.sparse\n",
    "        document_id=0\n",
    "        document_text=''\n",
    "        document_similarity=0\n",
    "        for j in range(len(pairwise_similarities[0])):\n",
    "            if pairwise_similarities[0,j]>0.9:\n",
    "                document_id=j\n",
    "                document_text=doc['text'][j]\n",
    "                document_similarity=pairwise_similarities[0,j]\n",
    "       \n",
    "        return document_id,document_text,document_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=userinput_pdfdocmatching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix,pairwise_similarities,pairwise_differences=x.tfidf_vectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.01688285, 0.227041  ])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'siddhanth parag mate               matesp cardiff ac uk   personalized linkedin url   github education cardiff  university   cardiff  united kingdom grad october      m sc  data science   analytics cardiff  university   cardiff  united kingdom grad september      b sc  mathematics   physics professional experience qpq  machine learning intern   cardiff  united kingdom july        october        individual task involved optimizing company s transactions   task solved using python libraries period four months client company   external datasets weather  foot traffic  events predict variables dataset provided company   task involved creating mlp neural network necessitate use classifier s optimize transaction data   model used tree based algorithms neural network predict transactions  trends foot traffic  locations items bought along trend based external factors fergusson college department physics  research intern   pune  india march        april        research assignment involved collecting data researcher   data task collected hospitals  medical centers   clinical facilities edelweiss general insurance company limited  intern   pune  united kingdom january        february        job required  searching new clients  promoting new insurance   wealth plans provided company customers   job involved undertaking ic   exam become insurance agent india leadership   experience machine learning university project  pre processing data   cardiff  united kingdom march        may        group six work topic  stock price prediction    individual task work data preprocessing data collection   task involved working twitter api  yahoo finance api  reddit api collect data process done period three months   collecting data multiple machine learning algorithms incorporated predict stock prices tweets  reddit sentiments past price history operation   research project  data analysis model simulation   cardiff  united kingdom september        october        involved creating simulation university faculty improve optimize function efficiently   individual task involved collecting data creating simulation using software simul  period one month hackathon  programming supervisor   pune  india june        june        event hosted group including students city showcase skills talent coding   robotics   task involved assuring functionality every participant s code working model presenting   event held period three days require personally look hundred different models code skills   interests technical  python  rstudio  sql  javascript  java  c    xml html  applied theoretical mathematics physics  ms word excel powerpoint  language  english fluent   hindi fluent   german  beginner  interest  kaggle coding competitions  deep learning projects  mathematics research reading   coding  learning web  languages  reading  competitive weightlifting  ji jistu  muay thai  flat     legacy tower london  united kingdom e    de',\n",
       " 0.9999999999999984)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_similar_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
